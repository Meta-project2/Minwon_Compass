import os
from app import database
from typing import List, Dict, Any
from openai import OpenAI

# í™˜ê²½ ë³€ìˆ˜ì—ì„œ í‚¤ ê°€ì ¸ì˜¤ê¸°
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

if not OPENAI_API_KEY:
    print("âš ï¸ ê²½ê³ : OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")

client = OpenAI(api_key=OPENAI_API_KEY)


class LLMService:
    def __init__(self):
        self.embed_model = "text-embedding-3-large"
        self.chat_model = "gpt-4o-mini"

    async def get_embedding(self, text: str) -> List[float]:
        """í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜"""
        try:
            text = text.replace("\n", " ")
            response = client.embeddings.create(
                input=[text],
                model=self.embed_model,
                dimensions=1024
            )
            return response.data[0].embedding
        except Exception as e:
            print(f"âŒ OpenAI ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
            return []

    async def generate_response(self, complaint_id: int, user_query: str = None, action: str = "chat") -> Dict[
        str, Any]:
        laws = []
        cases = []
        system_role = ""
        user_msg = ""

        # ë²•ë ¹ ì°¾ê¸° 
        if action == "search_law":
            print(f"ğŸ” [Button] ë¯¼ì› #{complaint_id} ë²•ë ¹ ê²€ìƒ‰")
            laws = database.search_laws_by_id(complaint_id, limit=3)

            context_text = ""
            for i, law in enumerate(laws, 1):
                title = law.get('title', 'ë²•ë ¹')
                content = law.get('chunk_text') or law.get('content', '')
                context_text += f"[{i}] {title}\n   ë‚´ìš©: {content[:400]}...\n\n"

            system_role = "ë‹¹ì‹ ì€ ë¯¼ì› ë²•ë ¹ ê²€ìƒ‰ ë„ìš°ë¯¸ì…ë‹ˆë‹¤. [ì°¸ê³  ìë£Œ]ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•µì‹¬ ê·œì •ì„ ìš”ì•½í•´ ì£¼ì„¸ìš”."
            user_msg = f"ì´ ë¯¼ì›ê³¼ ê´€ë ¨ëœ ë²•ë ¹/ê·œì •ì„ ì°¾ì•„ì¤˜.\n\n[ì°¸ê³  ìë£Œ]:\n{context_text}"

        elif action == "search_case":
            print(f"ğŸ” [Button] ë¯¼ì› #{complaint_id} ìœ ì‚¬ ì‚¬ë¡€ ê²€ìƒ‰")
            # DBì—ì„œ ìœ ì‚¬ ì‚¬ë¡€ ì¡°íšŒ
            raw_cases = database.search_cases_by_id(complaint_id, limit=3)

            print(f"   --> 1ì°¨ ê²€ìƒ‰ëœ ê°œìˆ˜: {len(raw_cases)}ê°œ")
            for idx, c in enumerate(raw_cases):
                print(f"   --> [í›„ë³´ {idx + 1}] ìœ ì‚¬ë„: {c.get('similarity')}% / ë‚´ìš©: {c.get('body')[:20]}...")

            # ìœ ì‚¬ë„ í•„í„°ë§
            cases = [c for c in raw_cases if c.get('similarity', 0) >= 00.0]
            if not cases:
                print("   --> ğŸš¨ í•„í„°ë§ í›„ ë‚¨ì€ ì‚¬ë¡€ê°€ 0ê°œì—¬ì„œ ì¦‰ì‹œ ë¦¬í„´í•©ë‹ˆë‹¤.")
                return {
                    "answer": "ê³¼ê±° ë°ì´í„° ë¶„ì„ ê²°ê³¼, í˜„ì¬ ë¯¼ì›ê³¼ ìœ ì‚¬ë„ê°€ ë†’ì€ ì²˜ë¦¬ ì‚¬ë¡€ê°€ ì—†ìŠµë‹ˆë‹¤. (ìœ ì‚¬ë„ 60% ì´ìƒ ê±´ ì—†ìŒ)",
                    "documents": []
                }
            # ì‚¬ë¡€ê°€ ìˆìœ¼ë©´ ìš”ì•½
            context_text = ""
            for i, case in enumerate(cases, 1):
                body = case.get('body', '')[:200]
                answer = case.get('answer', '')[:400]
                similarity = case.get('similarity', 0)
                context_text += f"[ì‚¬ë¡€ {i}] (ìœ ì‚¬ë„ {similarity}%)\n- ë¯¼ì›ë‚´ìš©: {body}...\n- ì²˜ë¦¬ê²°ê³¼: {answer}...\n\n"
            system_role = "ë‹¹ì‹ ì€ ë¯¼ì› ë¶„ì„ê°€ì…ë‹ˆë‹¤. ê³¼ê±° ìœ ì‚¬ ì‚¬ë¡€ë“¤ì˜ **ê³µí†µëœ ì²˜ë¦¬ ê²°ê³¼ì™€ ì¡°ì¹˜ ë‚´ìš©**ì„ í•µì‹¬ë§Œ ìš”ì•½í•´ì„œ ë³´ê³ í•´ ì£¼ì„¸ìš”."
            user_msg = f"ì´ ë¯¼ì›ê³¼ ìœ ì‚¬ë„ 60% ì´ìƒì¸ ê³¼ê±° ì‚¬ë¡€ {len(cases)}ê±´ì…ë‹ˆë‹¤. ì–´ë–»ê²Œ ì²˜ë¦¬ë˜ì—ˆëŠ”ì§€ ê²°ê³¼ë¥¼ ìš”ì•½í•´ì¤˜.\n\n[ê³¼ê±° ì‚¬ë¡€]:\n{context_text}"

        # ì±„íŒ… ê¸°ëŠ¥
        else:
            print(f"ğŸ” [Chat] ì‚¬ìš©ì ì§ˆë¬¸: {user_query}")
            if user_query:
                vec = await self.get_embedding(user_query)
                if vec:
                    laws = database.search_laws_by_text(vec, limit=3, keyword=user_query)

            context_text = ""
            for i, law in enumerate(laws, 1):
                title = law.get('title', 'ë²•ë ¹')
                content = law.get('chunk_text') or law.get('content', '')
                context_text += f"[{i}] {title}\n   ë‚´ìš©: {content[:400]}...\n\n"

            system_role = "ë‹¹ì‹ ì€ ë²•ë¥  ìƒë‹´ AIì…ë‹ˆë‹¤. [ì°¸ê³  ìë£Œ]ë¥¼ ê·¼ê±°ë¡œ ë‹µë³€í•˜ì„¸ìš”. ê·¼ê±°ê°€ ì—†ìœ¼ë©´ ì—†ë‹¤ê³  í•˜ì„¸ìš”."
            user_msg = f"ì§ˆë¬¸: {user_query}\n\n[ì°¸ê³  ìë£Œ]:\n{context_text}"

        # LLM í˜¸ì¶œ
        ai_answer = ""
        try:
            response = client.chat.completions.create(
                model=self.chat_model,
                messages=[
                    {"role": "system", "content": system_role},
                    {"role": "user", "content": user_msg}
                ],
                temperature=0.3
            )
            ai_answer = response.choices[0].message.content
        except Exception as e:
            ai_answer = f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

        return {
            "answer": ai_answer,
            "documents": laws if action != 'search_case' else cases  # ì‚¬ë¡€ ê²€ìƒ‰ì´ë©´ ì‚¬ë¡€ë¥¼ ë°˜í™˜
        }

    # AI ì´ˆì•ˆ ì‘ì„±
    async def generate_draft(self, complaint_id: int, complaint_body: str) -> str:

        past_answer = database.get_reference_answer(complaint_id)

        # ê´€ë ¨ ë²•ë ¹ ê²€ìƒ‰
        law_text = ""
        if complaint_body:
            vec = await self.get_embedding(complaint_body)
            if vec:
                laws = database.search_laws_by_text(vec, limit=3)
                # í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
                law_text = "\n\n".join([
                    f"- {law.get('title')} {law.get('section', '')}: {law.get('content', '')[:200]}..."
                    for law in laws
                ])

        system_role = "ë‹¹ì‹ ì€ ê°•ë™êµ¬ì²­ì˜ ë² í…Œë‘ ì£¼ë¬´ê´€ì…ë‹ˆë‹¤. ë¯¼ì›ì¸ì—ê²Œ ì •ì¤‘í•˜ê³  ëª…í™•í•˜ê²Œ ë‹µë³€í•´ì•¼ í•©ë‹ˆë‹¤."

        if past_answer:
            # ê³¼ê±° ë‹µë³€ì´ ìˆëŠ” ê²½ìš°
            prompt = f"""
            [ì§€ì‹œì‚¬í•­]
            ì•„ë˜ ì œê³µëœ 'ê³¼ê±° ìœ ì‚¬ ë‹µë³€'ì˜ **ë§íˆ¬, í˜•ì‹, ì¸ì‚¬ë§, ë§ºìŒë§ ìŠ¤íƒ€ì¼**ì„ ì² ì €íˆ ì°¸ê³ í•˜ì—¬,
            'í˜„ì¬ ë¯¼ì› ë‚´ìš©'ì— ëŒ€í•œ ë‹µë³€ ì´ˆì•ˆì„ ì‘ì„±í•´ì£¼ì„¸ìš”.

            ë‹¨, ì ìš©ë˜ëŠ” ë²•ì  ê·¼ê±°ëŠ” 'ê³¼ê±° ë‹µë³€'ì˜ ë‚´ìš©ì´ ì•„ë‹ˆë¼, ì•„ë˜ ì œê³µëœ 'ìµœì‹  ê´€ë ¨ ë²•ë ¹'ì„ ìš°ì„ ì ìœ¼ë¡œ ì¸ìš©í•´ì•¼ í•©ë‹ˆë‹¤.
            (ê³¼ê±° ë‹µë³€ì˜ ë²•ë ¹ì´ êµ¬í˜•ì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì£¼ì˜í•˜ì„¸ìš”.)

            [í˜„ì¬ ë¯¼ì› ë‚´ìš©]
            {complaint_body}

            [ìµœì‹  ê´€ë ¨ ë²•ë ¹ (Fact Checkìš©)]
            {law_text}

            [ì°¸ê³ í•  ê³¼ê±° ìœ ì‚¬ ë‹µë³€ (Style Reference)]
            {past_answer}

            [ì‘ì„±í•  ë‹µë³€]
            """
            warning_msg = ""
        else:
            # ê³¼ê±° ë‹µë³€ ì—†ëŠ” ê²½ìš°
            prompt = f"""
            [ì§€ì‹œì‚¬í•­]
            ì•„ë˜ 'ê´€ë ¨ ë²•ë ¹'ì„ ê·¼ê±°ë¡œ 'í˜„ì¬ ë¯¼ì› ë‚´ìš©'ì— ëŒ€í•œ ë‹µë³€ ì´ˆì•ˆì„ ì‘ì„±í•´ì£¼ì„¸ìš”.
            ì„œë¡ (ê³µê° ë° ì¸ì‚¬) - ë³¸ë¡ (ë²•ì  ê·¼ê±° ë° ë‹µë³€) - ê²°ë¡ (ë¬¸ì˜ì²˜ ì•ˆë‚´ ë° ë§ºìŒë§) í˜•ì‹ì„ ê°–ì¶°ì£¼ì„¸ìš”.

            [í˜„ì¬ ë¯¼ì› ë‚´ìš©]
            {complaint_body}

            [ê´€ë ¨ ë²•ë ¹]
            {law_text}

            [ì‘ì„±í•  ë‹µë³€]
            """
            warning_msg = "(ì•Œë¦¼: ìœ ì‚¬ ì‚¬ë¡€ê°€ ì—†ì–´ ë²•ë ¹ ê¸°ë°˜ìœ¼ë¡œë§Œ ì‘ì„±ë˜ì—ˆìŠµë‹ˆë‹¤.)\n\n"

        try:
            response = client.chat.completions.create(
                model="gpt-4o-mini", 
                messages=[
                    {"role": "system", "content": system_role},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3
            )
            draft_content = response.choices[0].message.content
            return warning_msg + draft_content

        except Exception as e:
            return f"ì˜¤ë¥˜ê°€ ë°œìƒí•˜ì—¬ ì´ˆì•ˆì„ ì‘ì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ({str(e)})"